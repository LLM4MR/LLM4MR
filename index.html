<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Large Language Model for Mixed Reality">
  <meta property="og:title" content="LLMR"/>
  <meta property="og:description" content="Large Language Model for Mixed Reality"/>
  <meta property="og:url" content="llm4mr.github.io"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/teaser2.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="LLMR">
  <meta name="twitter:description" content="Large Language Model for Mixed Reality">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/teaser2.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="llm, mixed reality, ai, interactive, 3d">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LLMR: Real-time Prompting of Interactive Worlds using Large Language Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/icon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">LLMR: Real-time Prompting of Interactive Worlds using Large Language Models</h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <span class="author-block">
                                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Fernanda De La Torre</a><sup>*1,2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://cathy-fang.com/" target="_blank">Cathy Mengying Fang</a><sup>*1,2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Han Huang</a><sup>*1,3</sup>,
                            </span>
                            <span class="author-block">
                                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Andrzej Banburski-Fahey</a><sup>1</sup>
                            </span>
                            <span class="author-block">
                                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Judith Amores</a><sup>1</sup>
                            </span>
                            <span class="author-block">
                                <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Jaron Lanier</a><sup>1</sup>
                            </span>

                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Microsoft,<br><sup>2</sup>Massachusetts Institute of Technology, <br><sup>3</sup>Rensselaer Polytechnic Institute  <br>2023</span>
                            <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- Arxiv PDF link -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/pdf/2309.12276v1.pdf" target="_blank"
                                       class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>System Paper (Accepted to ACM CHI 2024)</span>
                                    </a>
                                </span>

                                <!-- Supplementary PDF link -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/pdf/2310.17838.pdf" target="_blank"
                                       class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Animation Paper (Accepted to ML4CD 2023)</span>
                                    </a>
                                </span>
                                <!-- Github link -->
                                <span class="link-block">
                                    <a class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code (Coming Soon)</span>
                                    </a>
                                </span>
                                <!--
                                    <span class="link-block">
                                        <a href="https://github.com/YOUR REPO HERE" target="_blank"
                                           class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fab fa-github"></i>
                                            </span>
                                            <span>Code (Coming Soon)</span>
                                        </a>
                                    </span>-->
                                <!-- ArXiv abstract Link -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2309.12276" target="_blank"
                                       class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- Teaser video-->
    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                    <!-- Your video here -->
                    <source src="static/videos/llmr_preview_compressed.mp4"
                            type="video/mp4">
                </video>
                <h2 class="subtitle has-text-centered">
                    Teaser video
                </h2>
            </div>
        </div>
    </section>
    <!-- End teaser video -->
    <!-- Paper abstract -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->
    <!-- Image carousel -->
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/teaser.png" alt="This figure showcases various use cases and functionalities of LLMR, including creating a kitchen scene from scratch, drawing objects into existence, integrating with external plugins, editing existing VR scenes, generating instructional guides, and ensuring cross-platform compatibility. " />
                        <h2 class="subtitle has-text-centered">
                          <!--Old caption: Examples of diverse use cases and functionalities enabled by LLMR. A: Creation of a kitchen scene from scratch using Unity primitives. B: Prompting and drawing objects into existence via multi-modal interactions. C: Integration with external plugins like SketchFab to create high-fidelity scenes and prompting skills like animation creation. D: Edit existing VR scenes. E: Automated generation of instructional guides and QA with scene knowledge. F: Cross-platform compatibility and external sensor integration.
 -->
                            Examples of diverse use cases and functionalities enabled by LLMR. 
                        </h2>
                    </div>
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/access.png" alt="This figure demonstrates three examples of accessible interface features in a kitchen scene. The first example shows how the color scheme can be adjusted for red-green color-blind compatibility. The second example demonstrates the use of a magnifier tool to focus attention. The third example shows how objects deemed not kid-friendly can be hidden for safety and customization. " />
                        <h2 class="subtitle has-text-centered">
                          <!--                             Accessible Interface Features in Action. A1 and A2 show how a user can prompt the system to adjust the color scheme of a kitchen scene for red-green color-blind compatibility. B1 and B2 demonstrate the activation of a magnifier tool which can be used to focus attention. C1 and C2 reveal the option to hide objects deemed not kid-friendly, enhancing safety and customization.
 -->
                            LLMR can be used to make accessible interfaces from user prompts.
                        </h2>
                    </div>
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/gaming.png" alt="This figure showcases the cross-platform and cross-scene transferability of LLMR. It displays a car created by LLMR in three different scenarios: in a basic Unity scene, in a scene with moon-like gravity and terrain, and in a real-world scene controlled by a user's mobile phone. " />
                        <h2 class="subtitle has-text-centered">
                          <!--                             Cross-Platform and Cross-Scene Transferability made possible by LLMR. The left panel shows a car automatically created by LLMR using Unity primitives, complete with color and composite features (e.g. wheels and headlights), controllable via keyboard inputs. The middle panel displays the same car transferred to a different Unity scene featuring moon-like gravity and terrain. The right panel showcases the framework's adaptability across platforms by illustrating how the car can collide with objects in the physical world and can be controlled using IMU data from a user's mobile phone.
 -->
                            Cross-Platform and Cross-Scene Transferability made possible by LLMR. 
                        </h2>
                    </div>
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/creativity.png" alt="This figure demonstrates the use of LLMR in creating 3D models in VR. It shows a user requesting a magic paintbrush, drawing a chair with the paintbrush, and then generating multiple chair models using 2D-3D ControlNet and Dall·E-CLIP Sketchfab API." />
                        <h2 class="subtitle has-text-centered">
                          <!--Sketching objects into existence with LLMR. In the left panel, a user requests a "magic paintbrush" to be attached to a VR controller. The middle panel illustrates the automatic conversion of the line renderer into a paintbrush, where the user is shown drawing a chair. The right panel demonstrates the 2D-to-3D transformation using 2D-3D ControlNet and our Dall·E-CLIP Sketchfab API. This enables the generation of multiple chair models that can then be transferred across different platforms using LLMR for further interaction. -->
                            Sketching objects into existence with LLMR.
                        </h2>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End image carousel -->
    <!-- Youtube video -->
    <section class="hero is-small is-light">
         <div class="hero-body">
             <div class="container">
    <!-- Paper video. -->
            <h2 class="title is-3">Video Presentation</h2>
                <div class="columns is-centered has-text-centered">
                    <div class="column is-four-fifths">
                        <video poster="" id="tree" autoplay controls muted loop height="100%">
                            <!-- Your video here -->
                            <source src="static/videos/LLMR_CHI_VIDEO_compressed.mp4"
                                    type="video/mp4">
                        </video>
                        <!-- <div class="publication-video">  -->
    <!-- Youtube embed code here -->
                <!-- <iframe src="https://www.youtube.com/embed/6_9IcuKLwdc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
                        
                        <!-- </div> -->
                    </div>
                </div>
            </div>
        </div>
    </section>   
    <!-- End youtube video -->
    <!-- Paper abstract -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">How does LLMR work?</h2>
                    <div class="content has-text-justified">
                        <p>
                            LLMR is an orchestration of an ensemble of specialized GPTs. At its center is the BuilderGPT serving as an architect of C# Unity code for crafting interactive scenes. However, the multitude of tasks falling under virtual world creation renders a standalone coder insufficient. For instance, the ability to meaningfully modify an existing virtual world necessitates a profound semantic understanding of the scene. As humans, we have the ability to infer the properties of objects in the world and can refer to objects in the environment using demonstratives. To simulate the benefits of perceptual access, we incorporated the Scene Analyzer GPT. It generates a comprehensive summary of scene objects, offering detailed information when requested, including aspects like size, color, and the functionalities of interactive tools previously generated by LLMR. We also implemented the Skill Library GPT that determines the relevant skills that are needed for the Builder to accomplish the user’s request. In addition, we have observed that the code generated by the Builder lacks robustness and frequently contains bugs. To remedy this, we introduce the InspectorGPT, which evaluates the Builder's code against a predefined set of rules. This evaluation acts as a protective measure against compilation and run-time errors before the code is executed via the Roslyn Compiler.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->
    <!-- Image carousel -->
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/llmr_overview.png" alt="This figure shows the architecture of the LLMR system for real-time interactive 3D scene generation. It consists of a user prompt and an existing 3D scene as inputs, and a sequence of modules including the Planner, Scene Analyzer, Skill Library, Builder, Inspector, and Compiler. These modules work together to generate the desired 3D scene and functionalities in the Unity Engine. " />
                        <h2 class="subtitle has-text-centered">
                            LLMR architecture for real-time interactive 3D scene generation. 
                        </h2>
                    </div>
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/planner.png" alt="This figure shows the process of breaking down a user's high-level request into manageable subtasks. It includes a conversation between the user and the Planner, who determines the appropriate scope and granularity of each subtask. The Builder then executes the plan by generating code for each subtask. " />
                        <h2 class="subtitle has-text-centered">
                            The Planner and its role in breaking down a user's high-level request into a sequence of manageable subtasks.
                        </h2>
                    </div>
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/analyzer.png" alt="This figure shows the process of the LLMR Scene Analyzer. The input is a virtual scene in JSON format and the user request. The output is a filtered summary of the scene, which is used for conditioning subsequent modules. This process optimizes the utilization of the language model's fixed context window and enhances focus on objects relevant to the user prompt. " />
                        <h2 class="subtitle has-text-centered">
                            The virtual scene  is converted into a parsed scene hierarchy in JSON format. This, along with the user request, serves as input to the Scene Analyzer.
                        </h2>
                    </div>
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/builderInspector.png" alt="This figure illustrates the Builder-Inspector loop in LLMR, where the Builder module generates code based on user input and current state, and the Inspector module checks for errors and provides suggestions for corrections. The figure shows two iterations. " />
                        <h2 class="subtitle has-text-centered">
                            Builder-Inspector paradigm in LLMR. This feedback loop significantly enhances the quality of the generated scripts.
                        </h2>
                    </div>
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/skillLib.png" alt="A diagram representing the workflow of the Skill Library module. The module receives inputs from the Scene Analyzer and a user prompt, and then outputs the most relevant skills to the Builder for implementation." />
                        <h2 class="subtitle has-text-centered">
                            Skill Library module workflow.
                        </h2>
                    </div>
                    <div class="item">
                        <!-- Your image here -->
                        <img src="static/images/dalle.png" alt="This figure shows the Object Retriever pipeline for generating a 3D scene. The user inputs a prompt for a scene containing specific objects, and the pipeline uses DALL-E 2, Sketchfab API, and CLIP to find the best matches for each object and assemble them into a complete 3D scene. The output is a 3D scene with the specified objects arranged in a realistic manner. " />
                        <h2 class="subtitle has-text-centered">
                            Object Retriever pipeline for generating a 3D scene.
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End image carousel -->
    <!-- Paper abstract -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">
                        Real-time Animation Generation and Control on
                        Rigged Models via Large Language Models
                    </h2>
                    <div class="content has-text-justified">
                        <p>
                            We found that LLMR can be used to generate novel animations on a given 3D model using only natural language descriptions. Our method outputs structured strings encoding positional and rotational time series for each joint, which are parsed to produce animations on the rigged object. We showcase the generated animations on hierarchically distinct models with a variety of motions to underscore the robustness of our approach.
                            Separately, LLMR can be used to program animation transition on humanoid characters via the generation and execution of appropriate Unity C\# scripts. Our approach is characterized by its flexibility, allowing for the seamless integration of pre-existing animations with custom game logic.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->
    <!-- Teaser video-->
    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                    <!-- Your video here -->
                    <source src="static/videos/animations.mp4"
                            type="video/mp4">
                </video>
                <h2 class="subtitle has-text-centered">
                    One-shot and zero-shot generation of animations using Large Language Models
                </h2>
            </div>
        </div>
    </section>

    <!-- Video carousel -->
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container">
                <h2 class="title is-3">Additional videos</h2>
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-video1">
                        <video poster="" id="video1" autoplay controls muted loop height="100%">
                            <!-- Your video file here -->
                            <source src="static/videos/Participant_Generated_Results.mp4"
                                    type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-video2">
                        <video poster="" id="video2" autoplay controls muted loop height="100%">
                            <!-- Your video file here -->
                            <source src="static/videos/archer_walking.mp4"
                                    type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Controlling existing animations using LLMR
                        </h2>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End video carousel -->
    <!-- Paper poster -->
    <!--<section class="hero is-small is-light">
      <div class="hero-body">
        <div class="container">
          <h2 class="title">Poster</h2>

          <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
              </iframe>

          </div>
        </div>
      </section>-->
    <!--End paper poster -->
    <!--BibTex citation -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>
    @article{delatorre2023llmr,
    title={LLMR: Real-time Prompting of Interactive Worlds using Large Language Models},
    author={Fernanda De La Torre and Cathy Mengying Fang and Han Huang and Andrzej Banburski-Fahey and Judith Amores Fernandez and Jaron Lanier},
    year={2023},
    eprint={2309.12276},
    archivePrefix={arXiv},
    primaryClass={cs.HC}
    }

    @article{huang2023real,
    title={Real-time Animation Generation and Control on Rigged Models via Large Language Models},
    author={Huang, Han and De La Torre, Fernanda and Fang, Cathy Mengying and Banburski-Fahey, Andrzej and Amores, Judith and Lanier, Jaron},
    journal={arXiv preprint arXiv:2310.17838},
    year={2023}
    }
</code></pre>
        </div>
    </section>
    <!--End BibTex citation -->


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">

                        <p>
                            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">
                                Creative
                                Commons Attribution-ShareAlike 4.0 International License
                            </a>.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Statcounter tracking code -->
    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->
    <!-- End of Statcounter Code -->

</body>
  </html>
